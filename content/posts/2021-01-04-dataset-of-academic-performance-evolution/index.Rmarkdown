---
title: "Dataset of academic performance evolution"
author: "Brendan"
date: '2021-01-06'
slug: academicperf
draft: no
categories: []
tags: []
hero: /images/site/library.jpg
bibliography: biblo.bib
biblio-style: apalike
link-citations: yes
---



| Student Name   | Brendan Kent                  |
|----------------|-------------------------------|
| Student Number | C08861692                     |
| Class          | Prob. and Statistical Inference MATH9102 |
| Course         | TU060                         |

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(finalfit) # for ff_glimpse(df)
library(gridExtra)
```

```{css, echo=FALSE}
.toc .nav-link {
  font-size: 16px;
  line-height: 1;
  padding: 0;
  padding-left: 1;
  transition: all ease-out 0.3s;
  /* color: #1c2d41; */
}

li.nav-item {
    font-size: 16px;
}

pre {
    background-color: #f2f2f2;
    border-style: ridge;
}

```
#  Research Question

<blockquote class="blockquote">
What is the relationship between a student's overall average score for their professional evaluation in the final year of their professional career
in Engineering and their results obtained in the final year of high
school using five generic high school tests amongst students of Engineering in Columbia. The five tests are Mathematics (MAT_S11), Critical Reading (CR_S11), Citizen Competencies (CC_S11), Biology (BIO_S11) and English (ENG_S11). Consequently can these predictors be used to predict a student's overall average score in Engineering by linear regression and which predictors are the most influential.
</blockquote>

# Dataset

The dataset contains the results in national assessments for secondary and university
education in engineering students and contains academic, social, economic information for 12,411 students.
The data was collected as part of the Master's Degree in Engineering project of the Technological University of Bolívar (UTB) titled Academic Efficiency Analysis in Engineering students

A full descriptor is available at:
[https://www.sciencedirect.com/science/article/pii/S2352340920304315#utbl0001]()

The dataset is available for download at [https://data.mendeley.com/datasets/83tcx8psxv/1]()

```{r}
df <- read_excel("data_academic_performance.xlsx", sheet = "SABER11_SABERPRO")
df <- df %>% select(-"...10") # deselect this column
```

## Exploring variables in research question

The variable looks clean, no missing records as we can see below. The Saber 11 results are all marked to a maximum of 100 which some students have achieved. 
```{r paged.print=FALSE,warning=FALSE}
# ff_glimpse(df)
df %>%
  select(MAT_S11, CR_S11, CC_S11, BIO_S11, ENG_S11, G_SC) %>%
  ff_glimpse()
```

* the “level of Measurement” of each of these variables is Ratio, because the value 0 has a meaning. 

Since I prefer dealing with stardardized score, I will convert all these variables to z-scores. 

```{r}
df <- df %>% mutate(scale_MAT_S11 = scale(MAT_S11),
         scale_CR_S11 = scale(CR_S11),
         scale_CC_S11 = scale(CC_S11),
         scale_BIO_S11 = scale(BIO_S11),
         scale_ENG_S11 = scale(ENG_S11),
         scale_G_SC = scale(G_SC))
```

Next let's see the distribution of each:

```{r, paged.print=FALSE, results="hold", echo=FALSE, fig.align = "center", fig.height = 20, fig.cap="Five test results and overall grade in Engineering"}
p1 <- df %>%
  ggplot(aes(x=scale_MAT_S11)) +
  geom_histogram(binwidth=0.1, colour="black") +
  labs(title="Mathematics (MAT_S11) Histogram")
p1_1 <- df %>%
  ggplot(aes(sample = scale_MAT_S11)) + 
  stat_qq(size = 0.01) + 
  stat_qq_line() +
  labs(title="Mathematics (MAT_S11) Q-Q plot")
p2 <- df %>%
  ggplot(aes(x=scale_CR_S11)) +
  geom_histogram(binwidth=0.1, colour="black") +
  labs(title="Critical Reading (CR_S11) Histogram")
p2_1 <- df %>%
  ggplot(aes(sample = scale_CR_S11)) + 
  stat_qq(size = 0.01) + 
  stat_qq_line() +
  labs(title="Critical Reading (CR_S11) Q-Q plot")
p3 <- df %>%
  ggplot(aes(x=scale_CC_S11)) +
   geom_histogram(binwidth=0.1, colour="black") +
  labs(title="Citizen Competencies (CC_S11) Histogram")
p3_1 <- df %>%
  ggplot(aes(sample = scale_CC_S11)) + 
  stat_qq(size = 0.01) + 
  stat_qq_line() +
  labs(title="Citizen Competencies (CC_S11) Q-Q plot")
p4 <- df %>%
   ggplot(aes(x=scale_BIO_S11)) +
   geom_histogram(binwidth=0.1, colour="black") +
  labs(title="Biology (BIO_S11) Histogram")
p4_1 <- df %>%
  ggplot(aes(sample = scale_BIO_S11)) + 
  stat_qq(size = 0.01) + 
  stat_qq_line() +
  labs(title="Biology (BIO_S11) Q-Q plot")
p5 <- df %>%
  ggplot(aes(x=scale_ENG_S11)) +
   geom_histogram(binwidth=0.1, colour="black") +
  labs(title="English (ENG_S11) Histogram")
p5_1 <- df %>%
  ggplot(aes(sample = scale_ENG_S11)) + 
  stat_qq(size = 0.01) + 
  stat_qq_line() +
  labs(title="English (ENG_S11) Q-Q plot")
p6 <- df %>%
   ggplot(aes(x=scale_G_SC)) +
   geom_histogram(binwidth=0.1, colour="black") +
  labs(title="Overall average score (G_SC) Histogram")
p6_1 <- df %>%
  ggplot(aes(sample = scale_G_SC)) + 
  stat_qq(size = 0.01) + 
  stat_qq_line() +
  labs(title="Overall average score (G_SC) Q-Q plot")

grid.arrange(p1, p1_1, p2, p2_1, p3, p3_1, p4, p4_1, p5, p5_1, p6, p6_1, nrow = 6)
```

Assessing them for normality:

### Mathematics (MAT_S11)

```{r, paged.print=FALSE, echo=FALSE, results="hold", warning=FALSE}
skew_kurtosis <- function(name) {
  options(scipen=999)
  tpskew<-semTools::skew(name)
  tpkurt<-semTools::kurtosis(name)
  print(tpskew[1]/tpskew[2])
  print(tpkurt[1]/tpkurt[2])
}

skew_kurtosis(df$scale_MAT_S11)
```

Both skew and kurtosis are high. The cut off is +/- 1.96, anything above this is considered significant. Let's check the outliers:

```{r, paged.print=FALSE, echo=FALSE, results="hold", warning=FALSE}
outliers <- function(name) {
  zstabsences<- abs(name)
  cat("Percentage greater than 1.96 SDs:", FSA::perc(as.numeric(zstabsences), 1.96, "gt"),"% \n")
  cat("Percentage greater than 3.29 SDs:",FSA::perc(as.numeric(zstabsences), 3.29, "gt"), "%")
}
outliers(df$scale_MAT_S11)
```

Zero outliers outside the 3.29 SD of mean and less than 5% were outside of 1.96 SD of mean, so we can treat this variable as normal as since the sample size is so large (12411 records).

Report assessment of normality

<blockquote class="blockquote">
Mathematics (MAT_S11) scores was assessed for normality. Visual inspection of the histogram and QQ-Plot (see Figure 1) identified some issues with skewness and kurtosis. The standardised score for kurtosis (2.95) was considered unacceptable using the criteria proposed by West, Finch and Curran (1996), also the standardised score for skewness (18.17) was outside the acceptable range. However 100% of standardised scores for Mathematics (MAT_S11) fall within the bounds of +/- 3.29, using the guidance of Field, Miles and Field (2013) the data can be considered to approximate a normal distribution (m=64.3, sd=11.9, n=12411).
</blockquote>

### Critical Reading (CR_S11)

```{r, paged.print=FALSE, echo=FALSE, results="hold", warning=FALSE}
skew_kurtosis(df$scale_CR_S11)
```

Both skew and kurtosis are high. The cut off is +/- 1.96, anything above this is considered significant. Let's check the outliers:

```{r, paged.print=FALSE, echo=FALSE, results="hold", warning=FALSE}
outliers(df$scale_CR_S11)
```

Almost zero outliers outside the 3.29 SD of mean and about 5% were outside of 1.96 SD of mean, so we can treat this variable as normal as the data set is larger than 80 (12411 records). 

<blockquote class="blockquote">
Critical Reading (CR_S11) scores was assessed for normality. Visual inspection of the histogram and QQ-Plot (see Figure 1) identified some issues with skewness and kurtosis. The standardised score for kurtosis (10.87) was considered unacceptable using the criteria proposed by West, Finch and Curran (1996), also the standardised score for skewness (9.74) was outside the acceptable range. However 99.6% of standardised scores for Critical Reading (CR_S11) fall within the bounds of +/- 3.29, using the guidance of Field, Miles and Field (2013) the data can be considered to approximate a normal distribution (m=60.8, sd=10.0, n=12411).
</blockquote>

# Results 

In this section, I will being to put together a model to predict G_SC results. 

## Statistical Evidence

Before proceeding with linear regression, there are a few assumptions:
1. That there is a relationship, a linear one between the variables
2. Homoscedasticity (we can do this visually or with a test)
3. Independent observations
4. The residual errors should follow a normal distribution (this is the space between the linear line model and the data point)

For 1. we can check that a relationship exists. 

Correlation Scatter plot (MAT_S11 and G_SC):

```{r,warning=FALSE, fig.cap="Correlation Scatter plot (MAT_S11 and G_SC)", fig.align = "center"}
df %>%
  ggplot(aes(x=scale_MAT_S11, y=scale_G_SC)) +
  geom_point() + 
  geom_smooth(method = "lm", colour = "Green", se = F) + 
  labs(x = "Mathematics (MAT_S11)", y = "Overall average score (G_SC)") 
```

Doing a Pearson Correlation since both variables are a) continuous b) paired c) independent d) homoscedasticity is present and importantly e) the variables have a normal distribution. Fromt eh plot above, homoscedasticity is ok and we know the data matches the other criteria. 

```{r,warning=FALSE}
#Pearson Correlation
cor.test(df$scale_MAT_S11, df$scale_G_SC, method='pearson')
```

The correlation coefficient is a commonly used measure of the size of an effect: values of ±.1 represent a small effect, ±.3 is a medium effect and ±.5 is a large effect

To report Pearson coefficient here we say:

<blockquote class="blockquote">
`r length(df$scale_MAT_S11)` Mathematics (MAT_S11)(M=64.3, SD=11.9) high school results and a college Engineering overall score(G_SC) (M=162.7, SD=23.1) were investigated. A positive Pearson r correlation coefficient of 0.64 was revealed. There is strong correlation between Mathematics (MAT_S11) results and the college Engineering overall score(G_SC) with t(12409) = 93.733 and a p-value < 0.001. The size of the effect is large. 
</blockquote>

Now we know there is a strong relationship between the variables we can begin the model to use Mathematics (MAT_S11) scores to predict Engineering overall scores(G_SC). 

### Simple Linear Regression

Let's check and make sure the single predictor model is the same as the Pearson Correlation. 
```{r, warning=FALSE}
model1<-lm(df$scale_G_SC~df$scale_MAT_S11)
anova(model1)
summary(model1)
```

Findings:

* The p-value for ANOVA is exactly the same as the value we got for Pearson (p-value: < 0.00000000000000022). 
* The ANOVA summary command produces the Multiple R-squared result which is 0.4145,  so R = sqrt(0.4145) = 0.64 which is Pearson's R. 
* The R squared number can also tell us how much of the variation in G_SC results is explained by MAT_S11. So that's 41.5 % explained by High School Maths results. 
* The F-statistic result is (F(1, 12409) = 8786, p < .001), which is statistically significant. We can conclude that this regression model is significantly better at predicting the G_SC scores than if we used the mean value of G_SC. 

The final thing is to put together the equation of the line with the coefficient. 
```{r, warning=FALSE}
coef(model1)
```

The z-scale standardized equation is:
```
 G_SC = 0 + 0.64 * MAT_S11
```

### Mulpile Linear Regression

Now to add Critical Reading (CR_S11) to out model. Going back to the assumption for linear regression we first need to check for a correlation. 

Correlation Scatter plot (MAT_S11 and G_SC):

```{r,warning=FALSE, fig.cap="Correlation Scatter plot (CR_S11 and G_SC)", fig.align = "center"}
df %>%
  ggplot(aes(x=scale_CR_S11, y=scale_G_SC)) +
  geom_point() + 
  geom_smooth(method = "lm", colour = "Green", se = F) + 
  labs(x = "Critical Reading (CR_S11)", y = "Overall average score (G_SC)") 
```
```{r,warning=FALSE}
#Pearson Correlation
cor.test(df$scale_CR_S11, df$scale_G_SC, method='pearson')
```

The correlation coefficient is a commonly used measure of the size of an effect: values of ±.1 represent a small effect, ±.3 is a medium effect and ±.5 is a large effect

The correlation between Critical Reading (CR_S11) and overall score(G_SC) is statistically significant. 

To report Pearson coefficient here we say:

<blockquote class="blockquote">
`r length(df$scale_MAT_S11)` Critical Reading (CR_S11)(M=60.8, SD=10.0) high school results and a college Engineering overall score(G_SC) (M=162.7, SD=23.1) were investigated. A positive Pearson r correlation coefficient of 0.65 was revealed. There is strong correlation between Critical Reading (CR_S11) results and the college Engineering overall score(G_SC) with t(12409) = 96.193 and a p-value < 0.001. The size of the effect is large. 
</blockquote>

And now to add it to the first model that add just MAT_S11 to create a extended multiple linear regression model. 

A quick look at the simple linear regression model we created again:
```{r}
#Pearson Correlation
stargazer::stargazer(model1, type="text")
```

Adding Critical Reading (CR_S11) 
```{r}
model2<-lm(df$scale_G_SC~df$scale_MAT_S11+df$scale_CR_S11)
stargazer::stargazer(model2, type="text")
```

Some outcomes from model 2

* The Adjusted R squared has improved from 0.4145 to 0.523, meaning we can now explain more of variation in G_SC by including CR_S11 into our model
* CR_S11 is statically significant to p<0.01. 

One of the assumptions of a multiple linear regression model is that the residuals follow a normal distribution. We need to check this now on our model2. We can do this by finding any influential outliers by using cook's distance.

```{r,  echo=FALSE, results="hold", warning=FALSE, fig.cap="Cook's D for model2", fig.align = "center"}
#Influential Outliers - Cook's distance
cooksd<-sort(cooks.distance(model2))
# plot Cook's distance
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  
abline(h = 4*mean(cooksd, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),"*",""), col="red")  # add labels
```
```{r,  echo=FALSE, results="hold", warning=FALSE, fig.cap="Cook's D for model2", fig.align = "center"}
as_tibble(cooks.distance(model2)) %>%
  ggplot(aes(x=seq_along(value), y=value)) +
  geom_point(size=0.1) +
  geom_hline(yintercept = 4*mean(cooks.distance(model2), na.rm=T), col="red") +
  labs(x = "Record number", y = "Cook's distance") 
# + 
#  geom_text(x=1:length(cooks.distance(model2))+1, y=cooks.distance(model2), label=ifelse(cooks.distance(model2)>4*mean(cooks.distance(model2), na.rm=T),names(cooks.distance(model2)),""), col="red") 
```

Now to find rows related to influential observations, the ones above the line in the above figure:
```{r paged.print=FALSE,warning=FALSE}
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])  # influential row numbers
cat("Number of influencers:", length(influential), "\n")
cat ("20 influencers in MAT_S11",head(df[influential, ]$MAT_S11, n = 20),"\n")
cat ("20 influencers in CR_S11",head(df[influential, ]$CR_S11, n = 20),"\n")
cat ("Percentage of influencers: ", (length(influential) / nrow(df)) * 100, "% \n")
```
The total number of influential observations is less than 5% of the total. 

Bonferonni p-value for most extreme obs - Are there any cases where the outcome variable has an unusual variable for its predictor values?
```{r paged.print=FALSE,warning=FALSE}
car::outlierTest(model2)
```

* our model2 is telling us that these values above are unusual variables with very statistically significant results 


```{r,  echo=FALSE, results="hold", warning=FALSE, fig.cap="leverage plots for model2", fig.align = "center"}
car::leveragePlots(model2)
```

```{r,  echo=FALSE, results="hold", warning=FALSE, fig.cap="Assess homocedasticity for model2", fig.align = "center"}
plot(model2,1)
```

* We can see there is absolutely no heteroscedastity, we see a completely random, equal distribution of points throughout the range of X axis and a flat red line. There is no pattern in the residuals.

```{r,  echo=FALSE, results="hold", warning=FALSE, fig.cap="Histogram and density plot of the residuals for model2", fig.align = "center"}
plot(density(resid(model2))) 
```


# Discussion/Conclusion



